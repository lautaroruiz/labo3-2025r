{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ac89a5",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo LGBM hardcodeando los hiperparámetros seleccionados para el modelo final\n",
    "\n",
    "En esta notebook se ajusta el mdoelo LGBM sin realizar la optimización de hiperparámetros con optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43b6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e628bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/lauta/Desktop/Lautaro/maestria_ds/labo3/repo-entrega')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.utils import get_base_dir\n",
    "base_dir = get_base_dir()\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3549f",
   "metadata": {},
   "source": [
    "### 1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e867b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros a predecir: 780\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id\n",
       "0       20001\n",
       "1       20002\n",
       "2       20003\n",
       "3       20004\n",
       "4       20005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos a predecir\n",
    "predict_file = base_dir / \"data/predict/raw/product_id_apredecir201912.txt\"\n",
    "df_pred_orig = pd.read_csv(predict_file, sep=\"\\t\", encoding=\"utf-8\")\n",
    "print(f\"Registros a predecir: {df_pred_orig.shape[0]}\")\n",
    "df_pred_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d2dd110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((465660, 79), (12516572, 79), (4128320, 79))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leo directamente df_train, validation y predict\n",
    "df_train = pd.read_feather(base_dir / \"data/processed/df_train.feather\")\n",
    "df_validation = pd.read_feather(base_dir / \"data/processed/df_validation.feather\")\n",
    "df_predict = pd.read_feather(base_dir / \"data/processed/df_predict.feather\")\n",
    "\n",
    "# dimensiones particiones post-procesamiento\n",
    "df_predict.shape, df_train.shape, df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d491b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['venta_t-2', 'venta_t-3', 'venta_t-6',\n",
    "       'venta_t-9', 'venta_t-12', 'venta_t-24', 'media_3m', 'std_3m',\n",
    "       'suma_3m', 'max_3m', 'min_3m', 'media_6m', 'std_6m', 'suma_6m',\n",
    "       'max_6m', 'min_6m', 'media_9m', 'std_9m', 'suma_9m', 'max_9m', 'min_9m',\n",
    "       'media_12m', 'std_12m', 'suma_12m', 'max_12m', 'min_12m', 'media_24m',\n",
    "       'std_24m', 'suma_24m', 'max_24m', 'min_24m', 'pct_change_2_4m',\n",
    "       'pct_change_4_7m', 'tendencia_2_4m', 'tendencia_4_6m', 'venta_año_ant',\n",
    "       'mes_sin', 'mes_cos', 'trimestre_sin', 'trimestre_cos', 'es_enero',\n",
    "       'es_diciembre', 'es_verano', 'es_invierno', 'producto_media_historica',\n",
    "       'producto_volatilidad', 'cliente_media_historica', 'momentum_3m',\n",
    "       'momentum_6m', 'aceleracion', 'categoria_media', 'vs_categoria',\n",
    "       'marca_media', 'vs_marca', 'meses_sin_venta', 'frecuencia_compras_12m',\n",
    "       'VarMensualGral', 'VarMensualAlim', 'IndiceMensualGral',\n",
    "       'IndiceMensualAlim', 'dolar']\n",
    "numerical_features = new_cols + [\"mes\", \"año\", \"trimestre\", \"a_predecir\"]\n",
    "categorical_features = [\"product_id\", \"customer_id\", 'cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
    "model_features = numerical_features + categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6312b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria RAM disponible: 6.22 GB\n"
     ]
    }
   ],
   "source": [
    "# check memoria ram\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"Memoria RAM disponible: {mem.available / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c040cff",
   "metadata": {},
   "source": [
    "## Entrenar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c06679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's rmse: 0.748459\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's rmse: 0.749062\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's rmse: 0.753943\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's rmse: 0.752781\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[287]\tvalid_0's rmse: 0.748173\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's rmse: 0.750242\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[298]\tvalid_0's rmse: 0.751533\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[307]\tvalid_0's rmse: 0.748804\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 0.749294\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's rmse: 0.753271\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[286]\tvalid_0's rmse: 0.752355\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's rmse: 0.752849\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's rmse: 0.748452\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's rmse: 0.751766\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's rmse: 0.75041\n",
      "Métricas en validación:\n",
      "MAE: 0.0429 ± 0.0002\n",
      "RMSE: 0.7508 ± 0.0019\n",
      "Correlación: 0.6015 ± 0.0023\n"
     ]
    }
   ],
   "source": [
    "# Entrenar 15 modelos con diferentes semillas aleatorias\n",
    "best_params = {'learning_rate': 0.033298202348152534, 'num_leaves': 121, 'max_depth': 12, 'colsample_bytree': 0.7702280076072465, 'subsample': 0.9451048961270575, 'min_child_samples': 63, 'reg_alpha': 0.8261485784018764, 'reg_lambda': 0.2801548449048477, 'n_estimators': 335}\n",
    "\n",
    "n_models = 15\n",
    "models_list = []\n",
    "mae_valid_list = []\n",
    "rmse_valid_list = []\n",
    "correlation_list = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    best_model = lgb.LGBMRegressor(\n",
    "        **best_params,\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        boosting_type='gbdt',\n",
    "        random_state=42 + i,  # Diferente semilla para cada modelo\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    best_model.fit(\n",
    "        df_train[model_features], df_train[\"target\"],\n",
    "        eval_set=[(df_validation[model_features], df_validation[\"target\"])],\n",
    "        eval_metric='rmse',\n",
    "        categorical_feature=categorical_features,\n",
    "        callbacks=[lgb.early_stopping(50)]\n",
    "    )\n",
    "    models_list.append(best_model)\n",
    "    \n",
    "    # Predicciones en validación\n",
    "    y_pred_valid = best_model.predict(df_validation[model_features])\n",
    "\n",
    "    # Métricas de evaluación\n",
    "    mae_valid = mean_absolute_error(df_validation[\"target\"], y_pred_valid)\n",
    "    rmse_valid = np.sqrt(mean_squared_error(df_validation[\"target\"], y_pred_valid))\n",
    "    # Correlación entre predicciones y valores reales\n",
    "    correlation = np.corrcoef(df_validation[\"target\"], y_pred_valid)[0, 1]\n",
    "    \n",
    "    mae_valid_list.append(mae_valid)\n",
    "    rmse_valid_list.append(rmse_valid)\n",
    "    correlation_list.append(correlation)\n",
    "\n",
    "\n",
    "print(f\"Métricas en validación:\")\n",
    "print(f\"MAE: {np.mean(mae_valid_list):.4f} ± {np.std(mae_valid_list):.4f}\")\n",
    "print(f\"RMSE: {np.mean(rmse_valid_list):.4f} ± {np.std(rmse_valid_list):.4f}\")\n",
    "print(f\"Correlación: {np.mean(correlation_list):.4f} ± {np.std(correlation_list):.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c063a",
   "metadata": {},
   "source": [
    "## Predicciones para febrero 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "392b1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Productos en común con objetivo: 780 de 780\n"
     ]
    }
   ],
   "source": [
    "# obtener las predicciones según los modelos ajustados\n",
    "preds_ensemble = np.zeros(df_predict.shape[0])\n",
    "for model in models_list:\n",
    "    preds_ensemble += model.predict(df_predict[model_features])\n",
    "preds_ensemble /= n_models  # Promedio de predicciones\n",
    "\n",
    "# asignar en el conjunto df_predict\n",
    "df_predict[\"predicted_target\"] = preds_ensemble\n",
    "df_predict[\"predicted_tn\"] = df_predict[\"predicted_target\"] + df_predict[\"venta_t-2\"] # reconstruir tn\n",
    "\n",
    "# preparar resultados finales\n",
    "results_final = df_predict[[\n",
    "        'product_id', 'customer_id', 'periodo', 'predicted_tn'\n",
    "    ]].copy()\n",
    "results_final.columns = ['product_id', 'customer_id', 'periodo', 'tn']\n",
    "\n",
    "# check productos\n",
    "common_products = set(results_final['product_id']).intersection(set(df_pred_orig['product_id']))\n",
    "print(f\"Productos en común con objetivo: {len(common_products)} de {len(df_pred_orig)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "125decdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1108.548208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>1224.437310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>675.753929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>539.719046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>536.671452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>21263</td>\n",
       "      <td>0.694170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>21265</td>\n",
       "      <td>0.737044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>21266</td>\n",
       "      <td>0.738548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>21267</td>\n",
       "      <td>0.710705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>21276</td>\n",
       "      <td>0.695606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id           tn\n",
       "0        20001  1108.548208\n",
       "1        20002  1224.437310\n",
       "2        20003   675.753929\n",
       "3        20004   539.719046\n",
       "4        20005   536.671452\n",
       "..         ...          ...\n",
       "775      21263     0.694170\n",
       "776      21265     0.737044\n",
       "777      21266     0.738548\n",
       "778      21267     0.710705\n",
       "779      21276     0.695606\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agrupar predicciones a nivel producto\n",
    "df_prediction_grouped_product_id = df_predict.groupby(['product_id'])[\"predicted_tn\"].sum().reset_index()#.head(10)\n",
    "df_prediction_grouped_product_id.columns = [\"product_id\",\"tn\"]\n",
    "df_prediction_grouped_product_id = df_pred_orig.merge(df_prediction_grouped_product_id, on='product_id', how='left')\n",
    "df_prediction_grouped_product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165de7c8",
   "metadata": {},
   "source": [
    "## Guardar predicciones para subir a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1aa6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uso modelo solo para el top de productos (segun validation)\n",
    "top_productos = df_validation.groupby('product_id')['tn'].sum().reset_index().sort_values(by='tn', ascending=False).reset_index(drop=True)\n",
    "top_productos[\"tn_acum\"] = top_productos[\"tn\"].cumsum()\n",
    "top_productos[\"tn_acum\"] = top_productos[\"tn_acum\"] / top_productos[\"tn_acum\"].max() * 100\n",
    "top_productos = top_productos[top_productos[\"tn_acum\"] < 20][\"product_id\"].unique().tolist()\n",
    "\n",
    "predict_magicos = pd.read_csv(base_dir / f\"data/predict/final/product_id_clase_6_modelo_reg_simple_v1_magicos.csv\")\n",
    "df_prediction_grouped_product_id = df_prediction_grouped_product_id.merge(predict_magicos, on='product_id', how='left', suffixes=('', '_magico'))\n",
    "df_prediction_grouped_product_id[\"es_top\"] = df_prediction_grouped_product_id[\"product_id\"].isin(top_productos)\n",
    "\n",
    "# para el top me quedo con el original, sino el magico\n",
    "df_prediction_grouped_product_id[\"tn2\"] = df_prediction_grouped_product_id[\"tn\"].where(df_prediction_grouped_product_id[\"es_top\"], df_prediction_grouped_product_id[\"tn_magico\"])\n",
    "df_prediction_grouped_product_id = df_prediction_grouped_product_id[[\"product_id\",\"tn2\"]]\n",
    "df_prediction_grouped_product_id.columns = [\"product_id\",\"tn\"]\n",
    "\n",
    "time_tag = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M\")\n",
    "predict_file_processed = base_dir / f\"data/predict/final/predicciones_final_{time_tag}.csv\"\n",
    "df_prediction_grouped_product_id[[\"product_id\",\"tn\"]].to_csv(predict_file_processed, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5474620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1108.548208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>1224.437310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>675.753929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>539.719046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>536.671452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>21263</td>\n",
       "      <td>0.029993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>21265</td>\n",
       "      <td>0.089541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>21266</td>\n",
       "      <td>0.094659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>21267</td>\n",
       "      <td>0.092835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>21276</td>\n",
       "      <td>0.045447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id           tn\n",
       "0        20001  1108.548208\n",
       "1        20002  1224.437310\n",
       "2        20003   675.753929\n",
       "3        20004   539.719046\n",
       "4        20005   536.671452\n",
       "..         ...          ...\n",
       "775      21263     0.029993\n",
       "776      21265     0.089541\n",
       "777      21266     0.094659\n",
       "778      21267     0.092835\n",
       "779      21276     0.045447\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction_grouped_product_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo_3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
